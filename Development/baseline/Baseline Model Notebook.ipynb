{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import string\n",
    "import itertools\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from textstat.textstat import textstat as ts\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn import metrics as met\n",
    "\n",
    "sys.path.append('..')\n",
    "from text2num import text2num\n",
    "from util.load_data import JSONData\n",
    "from util.scores import ScoreReport\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constants & Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Constants and Parameters '''\n",
    "DATA_ROOT = '../../Data/dataset/'       # Root Folder of where Dataset Resides\n",
    "MODEL_ROOT = '../../Models/dataset/'    # Root Folder of where Model Resides\n",
    "K_FOLD = 10\n",
    "SHUFFLE_FOLDS = True\n",
    "np.random.seed(9892)                    # Seed Parameter for PRNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import and Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Import Data '''\n",
    "# Load Dataset\n",
    "data_load = JSONData(DATA_ROOT+'instances_train.jsonl', DATA_ROOT+'truth_train.jsonl', DATA_ROOT+'instances_test.jsonl')\n",
    "train_X = data_load.load_train_X()\n",
    "train_Y = data_load.load_train_Y()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_numeric(text):\n",
    "    try: return type(text2num(text)) == type(0)\n",
    "    except Exception as e: return False\n",
    "\n",
    "def pos_2gram(title, p1, p2):\n",
    "    pos_list = pos_tag(word_tokenize(title))\n",
    "    return sum(map(lambda x: x[0][1] == p1 and x[1][1] == p2, zip(pos_list[:-1], pos_list[1:])))\n",
    "\n",
    "def mean_wordlen(text):\n",
    "    word_lens = map(lambda x: map(lambda y: len(y), word_tokenize(x)), text)\n",
    "    return np.mean(list(itertools.chain.from_iterable(word_lens)))\n",
    "\n",
    "def max_wordlen(text):\n",
    "    word_lens = map(lambda x: map(lambda y: len(y), word_tokenize(x)), text)\n",
    "    return np.max(list(itertools.chain.from_iterable(word_lens)))\n",
    "\n",
    "nnp_num = lambda x: sum(map(lambda y: y[1] == 'NNP', pos_tag(word_tokenize(x))))\n",
    "wlen_title = lambda text: len(filter(lambda x: x.isalpha(), word_tokenize(text)))\n",
    "num_start = lambda x: x[0].isdigit() or is_numeric(x[0])\n",
    "in_num = lambda t: sum(map(lambda x: x[1] == 'IN', pos_tag(word_tokenize(t))))\n",
    "wrb_num = lambda t: sum(map(lambda x: x[1] == 'WRB', pos_tag(word_tokenize(t))))\n",
    "nnp_num = lambda t: sum(map(lambda x: x[1] == 'NN', pos_tag(word_tokenize(t))))\n",
    "wh_start = lambda t: word_tokenize(t)[0].lower() in ['who', 'what', 'why', 'where', 'when', 'how']\n",
    "qm_exist = lambda t: sum(map(lambda x: str(x) == '?', word_tokenize(t))) > 0\n",
    "\n",
    "def preprocess(x):\n",
    "    print('PROCESSING ID: ' + str(x['id']))\n",
    "    fvec = []\n",
    "    fvec.append(nnp_num(x['targetTitle']))\n",
    "    if len(x['targetParagraphs']) > 0:\n",
    "        fvec.append(ts.automated_readability_index(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.avg_letter_per_word(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.avg_sentence_length(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.avg_sentence_per_word(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.avg_syllables_per_word(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.char_count(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.coleman_liau_index(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.dale_chall_readability_score(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.difficult_words(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.flesch_kincaid_grade(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.flesch_reading_ease(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.gunning_fog(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.lexicon_count(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.linsear_write_formula(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.polysyllabcount(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.sentence_count(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.smog_index(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(ts.syllable_count(' '.join(x['targetParagraphs'])))\n",
    "        fvec.append(mean_wordlen(x['targetParagraphs']))\n",
    "    else:\n",
    "        fvec += [0]*19\n",
    "    if len(x['postText']) > 0:\n",
    "        fvec.append(max_wordlen(x['postText']))\n",
    "    else:\n",
    "        fvec += [0]*1\n",
    "    fvec.append(len(word_tokenize(x['targetTitle'])))\n",
    "    fvec.append(wlen_title(x['targetTitle']))\n",
    "    fvec.append(pos_2gram(x['targetTitle'], 'NNP', 'NNP'))\n",
    "    fvec.append(int(num_start(x['targetTitle'])))\n",
    "    fvec.append(in_num(x['targetTitle']))\n",
    "    fvec.append(pos_2gram(x['targetTitle'], 'NNP', 'VBZ'))\n",
    "    fvec.append(pos_2gram(x['targetTitle'], 'IN', 'NNP'))\n",
    "    fvec.append(wrb_num(x['targetTitle']))\n",
    "    fvec.append(nnp_num(x['targetTitle']))\n",
    "    fvec.append(int(wh_start(x['targetTitle'])))\n",
    "    fvec.append(int(qm_exist(x['targetTitle'])))\n",
    "    return fvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4a2b1a4995a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Finalize Feature and Target Vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'truthClass'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no-clickbait'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mY_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'truthClass'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no-clickbait'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    248\u001b[0m         '''\n\u001b[1;32m    249\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mRUN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "# Finalize Feature and Target Vectors\n",
    "p = Pool(32)\n",
    "X = np.array(p.map(preprocess, train_X))\n",
    "Y = np.array(map(lambda x: [0] if x['truthClass'] == 'no-clickbait' else [1], train_Y))\n",
    "Y_ = np.array(map(lambda x: 0 if x['truthClass'] == 'no-clickbait' else 1, train_Y))\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alternative Score Reporting Function\n",
    "def report_score(y_true, y_pred, y_prob):\n",
    "    print(\"Mean squared error: \" + str(met.mean_squared_error(y_true, y_pred)))\n",
    "    print(\"R^2: \" + str(met.r2_score(y_true, y_pred)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n",
      "\n",
      "[K = 1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-39e43bc6c35a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Train Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mgnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mgnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Generate Predictions & Confidence Estimates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yjo5006/.local/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \"\"\"\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    185\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32m/home/yjo5006/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    541\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    543\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/home/yjo5006/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                       force_all_finite)\n\u001b[1;32m    401\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# K-Fold and Score Tracking\n",
    "kf = StratifiedKFold(n_splits=K_FOLD, shuffle=SHUFFLE_FOLDS)\n",
    "\n",
    "print('Training Model...')\n",
    "for i, (train_idx, test_idx) in enumerate(kf.split(X, Y_)):\n",
    "    print('\\n[K = ' + str(i+1) + ']')\n",
    "    ''' SMOTE - Generate Synthetic Data '''\n",
    "    # sm = SMOTE(kind='regular')\n",
    "    # X_resampled = []\n",
    "    # X_res, Y_res = sm.fit_sample(X[train_idx], Y[train_idx])\n",
    "\n",
    "    # Train Model\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X[train_idx], Y[train_idx])\n",
    "\n",
    "    # Generate Predictions & Confidence Estimates\n",
    "    y_pred = gnb.predict(X[test_idx])\n",
    "    y_prob = gnb.predict_proba(X[test_idx])\n",
    "    y_prob = map(lambda x: x[1][x[0]], zip(y_pred, y_prob))\n",
    "    \n",
    "    # Append to Report\n",
    "    # report.append_result(Y[test_idx].reshape(y_pred.shape), y_pred, y_prob)\n",
    "    \n",
    "    # Alternative Score Reporting\n",
    "    report_score(Y[test_idx].reshape(y_pred.shape), y_pred, y_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
